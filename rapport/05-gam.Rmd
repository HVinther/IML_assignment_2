
```{r, include = FALSE}
dir("utils", full.names = T) |>
  sort(decreasing = T) |>
  lapply(source)
```


# Interpretable model

As an interpretable model we propose using a GAMs for both the regressor and classifier part of the custom learner described in section "Improved Learner", ie. the severity/frequency model. For both models, no interactions effects will be included, as to increase the interpretability, while probaly sacrificing accuracy. The regressor part in particular should be quite interpretable as it is additive since the link function is the identity. The classifier part of course includes a link function not equal to the identity, ie. logit, sacrificing a bit of the interpretability. 

Now for both parts a sigmoid transformation of Exposure is used as a weigthing (as described in the first project). The date features are removed as they conflict with some of the functions used for interpretability. The social category and vehicle price features are transformed to numeric by the adhoc encoding described in the first project. Then all numerics are included using smooths (ie. splines created with the `s` function from `mgcg`), and integers, logicals and factors are dummy encoded. Note, the vehicle age is included as a factor instead of a numeric due to its low number of unique values, which causes some problems with degrees of freedom.

The only difference in the preprocessing steps between the two parts, is the inclusion of the `po("classbalancing")` node in the classifier, which resamples during training such that the frequency of the responses are similar.

## Shapley plots for desired indices

Six observations from the testing set is desired explained, thus a local explanation is attempted here using their shapley plots. We create these plots both for the full model and its two components. The plots for a given index can be inspected using the dropdown menu below.

Recall, that shapley plots attempt to explain the predictor locally as consisting of linear components, thus the plots for the regression model can be read as is, while the reader should keep in mind that the remaining to are non-linear.

As a general note, we see that neither gender nor marital status are a part of the ten features with the largest impact for any of the observations.

```{r,echo = FALSE}
sp_list<-readRDS("save_files/gam_shapley.rds")[[2]]
```

### Sharpley plots{.tabset .tabset-dropdown}

#### Observation 1386

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[1]]$p_full+
    ggtitle("Full model"),
  sp_list[[1]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[1]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```




#### Observation 12286

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[2]]$p_full+
    ggtitle("Full model"),
  sp_list[[2]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[2]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```


#### Observation 2119

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[3]]$p_full+
    ggtitle("Full model"),
  sp_list[[3]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[3]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```


#### Observation 2238

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[4]]$p_full+
    ggtitle("Full model"),
  sp_list[[4]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[4]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```




#### Observation 27833

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[5]]$p_full+
    ggtitle("Full model"),
  sp_list[[5]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[5]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```

#### Observation 27988

```{r, fig.width = 12, fig.height = 14,echo = FALSE}
gridExtra::grid.arrange(
  sp_list[[6]]$p_full+
    ggtitle("Full model"),
  sp_list[[6]]$p_regr+
    ggtitle("Regression model"),
  sp_list[[6]]$p_classif+
    ggtitle("Classifier model"),
  nrow = 3
)
```

###

## Global explanation 

Apart from the local explanation described in the section before, we can also study global behaviour using partial dependency plots. These pdp plots can be viewed for both the full model as well as its components using the dropdown menu below.

Note, that the shape of the dependence for different variables changes between the components of the model. Now, as some of preprocessing of the features is done in side the learners, some features which actually ends up enterings as numerics and thus with smooths, are not included. This is mainly down to implementation. Optimally these should be studied as well.

### Partial dependency plots {.tabset .tabset-dropdown}

```{r,fig.width = 12, fig.height = 14,echo = FALSE}
pdp<-readRDS("save_files/gam_pdp.rds")
```

#### full model

```{r,fig.width = 12, fig.height = 14,echo = FALSE}
pdp$full+
  ylim(c(-1000,5500))
```

#### Classifier model

```{r,fig.width = 12, fig.height = 14,echo = FALSE}
pdp$classif
```

#### Regression model

```{r,fig.width = 12, fig.height = 14,echo = FALSE}
pdp$regr
```

###

Here follows a few comments for each of the features.

<dl class="dl-horizontal">
<dt>BonusMalus:</dt>
<dd>We see that for the full model, BonusMalus has a positive to no effect, with the highest effect achieved at about 120. Considering the components, this seems to be a results mainly of the classifier component, as the predicted amount from the regressor is almost constant, while the classifier has a big well around 200. </dd>
<dt>DrivAge:</dt> 
<dd> In the full model the driver age seem to have quite a big impact on the predicted claimed amount, with middleaged individuals having a lower predicted claim amount, while youngsters and elders have a higher predicted claim amount. </dd>
<dt>Exposure:</dt>
<dd>Exposure seems to have the largest impact in the classifier component, where a higher level of exposure leads to a higher probability of a claim, while for the regressor a decreasing tendency is observed.</dd>
<dt>LicAge:</dt>
<dd> The licence age have some quite wild tail behavior. The regressor component seems to be dragging the predictions for higher ages under the full model down below zero. The classifier component of course also predicts a high chance of claim for older licenses.</dd>
<dt>Riskvar</dt>
<dd> This feature has a slightly increasing positive impact across all components, as well as the full model.</dd>
<dt>HasKmLimit</dt>
<dd> Note, in the model this inters as a factor, and the difference between the two levels seems to be rather small across the components. </dd>
</dl>

### Average response based on gender and mariage status {.tabset .tabset-dropdown}

To inspect if a bias in the model exists with respect to the features gender and marital status, we inspect the prediction on the test set. We plot both the average prediction with a standard 95% confidence interval as well as a simple boxplot of the prediction. These are stratied by the chosen feature in dropdown menu. Note, a plot for each component of the model as well as for the full model is made.

```{r,fig.width = 10, fig.height = 5, echo = FALSE}
loadData()

sgl<-readRDS("modeller/seq_gam_lrn.rds")

df_gam<-test %>% mutate(
  full = test[,-c(3,4)] %>%
    mutate(ClaimInd = as.factor(ClaimInd)) %>%
    as_task_regr(target = "ClaimAmount") %>%
    sgl$predict(.) %>%
    .$response,
  regr = test[,-c(3,4)] %>% 
    select(-"ClaimInd") %>%
    as_task_regr(target = "ClaimAmount") %>%
    sgl$regr_model$predict(.) %>%
    .$response,
  classif = test[,-c(3,4)] %>% 
    select(-"ClaimAmount") %>% 
    mutate(ClaimInd = as.factor(ClaimInd)) %>%
    as_task_classif(target = "ClaimInd") %>%
    sgl$classif_model$predict(.) %>%
    .$prob %>%
    .[,2]
) %>%
  pivot_longer(cols = c("full","regr","classif"))
```

#### Gender

```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  group_by(Gender, name) %>%
  summarize(
    mean_pred = mean(value),
    std_error = sd(value),
    lower_ci = mean_pred - (std_error * 1.96),
    upper_ci = mean_pred + (std_error * 1.96)
  ) %>%
  ungroup()%>%
  ggplot() +
  # Error bars with adjusted width and color
  geom_errorbar(mapping=aes(x=Gender, y=mean_pred, ymin=lower_ci, ymax=upper_ci), 
                width=0.2, color="darkgray", linewidth=0.8) +
  # Points with increased size and color differentiation
  geom_point(mapping=aes(x=Gender, y=mean_pred, color=Gender), size=4, alpha=0.8) +
  
  # Customizing the plot with labels and title
  labs(x = "Gender", 
       y = "Mean Prediction", 
       title = "Mean claim amount by Gender",
       subtitle = "Includes 95% confidence intervals") +
  
  # Theme customization for a cleaner look
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",  # Remove legend if color differentiation by Gender is not needed
        plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12),
        axis.title.x = element_text(vjust = -0.2),
        axis.title.y = element_text(vjust = 1.2)) +
  
  # Optional: Customize colors manually if desired
  #scale_color_manual(values = c("Male" = "#1f77b4", "Female" = "#ff7f0e"))+
  facet_wrap(~name, scales = "free")
```

```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  ggplot(aes(y = value, 
             x = Gender,
             fill = Gender))+
  geom_boxplot()+
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        axis.text.x=element_text(angle=30, vjust = 1, hjust = 1))+
  labs(x = "", 
       y = "Prediction", 
       title = "Claim amount by Gender")+
  facet_wrap(~name, scales = "free")
```

#### Maristat

```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  group_by(MariStat, name) %>%
  summarize(
    mean_pred = mean(value),
    std_error = sd(value),
    lower_ci = mean_pred - (std_error * 1.96),
    upper_ci = mean_pred + (std_error * 1.96)
  ) %>%
  ungroup()%>%
  ggplot() +
  # Error bars with adjusted width and color
  geom_errorbar(mapping=aes(x=MariStat, y=mean_pred, ymin=lower_ci, ymax=upper_ci), 
                width=0.2, color="darkgray", linewidth=0.8) +
  # Points with increased size and color differentiation
  geom_point(mapping=aes(x=MariStat, y=mean_pred, color=MariStat), size=4, alpha=0.8) +
  
  # Customizing the plot with labels and title
  labs(x = "Marital status", 
       y = "Mean Prediction", 
       title = "Mean claim amount by marital status",
       subtitle = "Includes 95% confidence intervals") +
  
  # Theme customization for a cleaner look
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",  # Remove legend if color differentiation by Gender is not needed
        plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12),
        axis.title.x = element_text(vjust = -0.2),
        axis.title.y = element_text(vjust = 1.2)) +
  
  # Optional: Customize colors manually if desired
  #scale_color_manual(values = c("Alone" = "#1f77b4", "Other" = "#ff7f0e"))+
  facet_wrap(~name, scales = "free")
```
```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  ggplot(aes(y = value, 
             x = MariStat,
             fill = MariStat))+
  geom_boxplot()+
  xlab("")+
  theme_minimal(base_size = 14)+
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        axis.text.x=element_text(angle=30, vjust = 1, hjust = 1))+
  labs(x = "", 
       y = "Prediction", 
       title = "Claim amount by marital status")+
  #scale_fill_manual(values = c("Alone" = "#1f77b4", "Other" = "#ff7f0e"))+
  facet_wrap(~name, scales = "free")
```

#### Interaction

```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  group_by(interaction(MariStat,Gender), name) %>%
  summarize(
    mean_pred = mean(value),
    std_error = sd(value),
    lower_ci = mean_pred - (std_error * 1.96),
    upper_ci = mean_pred + (std_error * 1.96)
  ) %>%
  ungroup()%>%
  ggplot() +
  # Error bars with adjusted width and color
  geom_errorbar(mapping=aes(x=`interaction(MariStat, Gender)`, y=mean_pred, ymin=lower_ci, ymax=upper_ci), 
                width=0.2, color="darkgray", linewidth=0.8) +
  # Points with increased size and color differentiation
  geom_point(mapping=aes(x=`interaction(MariStat, Gender)`, y=mean_pred, color=`interaction(MariStat, Gender)`), size=4, alpha=0.8) +
  
  # Customizing the plot with labels and title
  labs(x = "Marriage Status and Genders", 
       y = "Mean Prediction", 
       title = "Mean claim amount by MariStatus.Gender",
       subtitle = "Includes 95% confidence intervals") +
  
  # Theme customization for a cleaner look
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",  # Remove legend if color differentiation by Gender is not needed
        plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12),
        axis.title.x = element_text(vjust = -0.2),
        axis.title.y = element_text(vjust = 1.2),
        axis.text.x=element_text(angle=30, vjust = 1, hjust = 1)) +
  
  # Optional: Customize colors manually if desired
  #scale_color_manual(values = c("Alone.Female" = "darkred", "Other.Female" = "salmon",Alone.Male="darkblue",Other.Male="cyan"))+
  facet_wrap(~name, scales = "free")
```
```{r,fig.width = 10, fig.height = 5, echo = FALSE, message = FALSE, warning = FALSE}
df_gam %>%
  ggplot(aes(y = value, 
             x = interaction(MariStat,Gender),
             fill = interaction(MariStat,Gender)))+
  geom_boxplot()+
  theme_minimal(base_size = 14) +
  theme(legend.position = "none",
        axis.text.x=element_text(angle=30, vjust = 1, hjust = 1),
        plot.title = element_text(face = "bold", size = 16))+
  labs(x = "", 
       y = "Prediction", 
       title = "Claim amount by interacion between marital status and gender")+
  #scale_fill_manual(values = c("Alone.Female" = "darkred", "Other.Female" = "salmon",Alone.Male="darkblue",Other.Male="cyan"))+
  facet_wrap(~name, scales = "free")
```

### 

Over all, we see very little difference in the predictions between the different levels of the inspected features. Especially the classification part seems to make almost no discrimination. Slight discrimination might happen in the regression part with regards to the marital status, where a lower mean prediction as well as a tighter confidence band is seen for the alone level as well as interactions with this. Thus we would expect a debiasing of the model in regards to these features would make very little change to the predicted claim amounts.

We could of course also inspect the coefficients of the components models. As the regression model is additive the effect can be read directly.

```{r, echo = FALSE}
sgl$regr_model$model$regr.gam$model %>%
  coefficients()%>%
  {
    ins = .
    Gen = stringr::str_detect(string = names(ins),pattern = "Gender",negate = F)
    Mar = stringr::str_detect(string = names(ins),pattern = "MariStat",negate = F)
    ins[Gen | Mar]
  }
```
We see that the direct impact of these features is that females get a predicted claim amount of about 11 more than men, while difference with respect to marital status is about 55. Given that the average predicted claim amount is in the thousands these differences are minute. Of course, there might still exist some bias due to indirect effects.

Now, considering the classifier component the equivalent coefficients can be extracted. However, as this model includes a link function the interpretation is not as straight forward as with the regression component.

```{r, echo = FALSE}
sgl$classif_model$model$classif.gam$model%>%
  coefficients()%>%
  {
    ins = .
    Gen = stringr::str_detect(string = names(ins),pattern = "Gender",negate = F)
    Mar = stringr::str_detect(string = names(ins),pattern = "MariStat",negate = F)
    ins[Gen | Mar]
  }
```
Still we note very small impacts of these features. Although both females and a marital status of alone leads to a slight increase in predicted probability of a claim.

### Debiasing

For debiasing our model we use fairness via the average natural direct effect. To debias our model we therefore run four predictions on our test data, one with each interaction of our protected variables, and then take the average predicted value.

```{r}
pred_seq_gam_db <- readRDS("gam_db_pred")

unbiased <- cbind(test_new,pred_seq_gam_db)

pred_full <- data.frame( prediction = seq_gam$predict(test_task)$response)

unbiased$model <- "unbiased"

biased <- cbind(test_new,pred_full)

biased$model <- "biased"

both <- rbind(unbiased,biased)

ggplot(both)+
  geom_boxplot(mapping = aes(y=prediction, x=interaction(Gender, MariStat),fill = model))

```
We can see here that we did manage debias our model, but the GAM model were already quite unbiased so we can't see a big difference in the two plots.