# Interpretable model

As an interpretable model we propose using a GAMs for both the regressor and classifier part of the custom learner described in section "Improved Learner", ie. the severity/frequency model. For both models, no interactions effects will be included, as to increase the interpretability, while probaly sacrificing accuracy. The regressor part in particular should be quite interpretable as it should be additive since the link function should be the identity. The classifier part of course includes a link function not equal to the identity, sacrificing a bit of the interpretability. 

Now for both parts a sigmoid transformation of Exposure is used as a weigthing (as described in the first project). The date features are removed as they conflict with some of the functions used for interpretability. The social category and vehicle price features are transformed to numeric by the adhoc encoding described in the first project. Then all numerics are included using smooths (ie. splines created with the `s` function from `mgcg`), and integers, logicals and factors are dummy encoded. Note, the vehicle age is included as a factor instead of a numeric due to its low number of unique values, which causes some problems with degrees of freedom.

The only difference in the preprocessing steps between the two parts, is the inclusion of the `po("classbalancing")` node in the classifier, which resamples during training such that the frequency of the responses are similar.

