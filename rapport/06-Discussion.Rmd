# Discussion

One of the most insightful things about this project has been the implementation of the custom learner. Although it took some time to create, it has been invaluable for all of the methods that follows with a learner object in mlr3, such as generation of local and global explainers in the form of shapley values and partial dependence plots.

To compare the models, we can first look at the feature importance to get a general idea of how the features have an impact on the predictions. Most notably, exposure and BonusMalus is by far most important to the random forest, and not so important for the GAM. On the other hand, the GAM prioritize driver age and license age.

One might object to the way we have treated driver age and license age, since these are highly correlated (cor=0.93). Especially for the GAM, this may lead to some overfitting, while it is difficult to say what the impact on the random forest is. To remedy this, we might have considered ALE plots in addition to the PDP. There is the unique nuance to license age that everyone is at least 18 when they get their license, some are older but none are younger, so the correlation structure is not clear. This might make the interpretability from ALE plots more difficult as well.

The random forest and the GAM predict vastly different probabilities, which in large part impacts the predicted claim amount. This difference stems somewhat from the balancing that was done for the GAM, but this was necessary for the GAM to even predict any claims. Since we do not have any interactions in the GAM, the predictions are not as strong as they are for the random forest. On the other hand, there is much less overfitting in the GAM, making the picture somewhat clearer. We see that driver and license ages have somewhat the same impact across both models, with GAM telling us that pensioneers have very high claim amounts. The dip around 90 should not be given too much significance, since <0.2% of data is in this area. They disagree on the impact of high values BonusMalus and the impact of a speed limit. We do not really have a good understanding of BonusMalus, so it is hard to say which predictions seem more reasonable, but the picture is much clearer for GAM. For the speed limit, we would have to investigate if it is associated with generally fast cars (more accidents) or that it leads to cars which on average don't go above the speed limit as often (fewer accidents).

It might be reasonable to include some smoothing on the PDP for random forest so it looks less overfitted, although this would not be representative of the true model fitted.

If we consider the effects of gender and marriage status, it does not appear to have a significant effect on the predictions. It seems like GAM even has the lowest bias out of the gate, but that it can be mitigated even more by debiasing. 

When looking at the shapley values in the test data, we see that the GAM struggles. While this data is all for people who have made no claims, GAM estimate their claim amounts in the thousands of euros. Random forest does not have this problem. The shapleys are generally pretty consistent with the global explanations we have found. It is not clear if the smoothness of the PDP for GAM is worth it compared to its poor predictive performance, and some interactions should probably be included to make it competetive with the random forest for prediction. We also note that GAM is fine with negative claim amounts, while random forest only looks in the area it has fitted to.

When looking at the PDP, it is evident that the final prediction is a product of two models which do not always agree. For example the effect of age in classification versus regression for GAM. One might also consider that simply taking the product of the probability from classification and the claim amount from regression is just the simplest way of using both of them. We might add some weights $a$ and $b$ and consider $\hat{C}_i=((\hat{p}_i)^a\cdot \hat{C}_{1i})\cdot b$ to adjust the weighting of the probability directly and the scale of the claim amount. This should not be super difficult to implement in the learner, and could just be auto tuned using standard mlr3 functionality. 

For interpredability no interactions were included in the gam modelling. However, to this is an obviouos path to consider to increase the predictive performance, by sacrificing af bit of interpredatability.